{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Training ResNet with different images (synthetic or not)"
      ],
      "metadata": {
        "id": "vqPfpsNQkIAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk56vquZjx0A",
        "outputId": "ffbcae90-c9b1-4580-9029-8dd2afadccda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/College/ece661/Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/College/ece661/Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "CHECKPOINT_FOLDER = '/content/drive/MyDrive/College/ece661/Project/saved_model'\n",
        "if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "    os.makedirs(CHECKPOINT_FOLDER)"
      ],
      "metadata": {
        "id": "Qiqm5WdgkUaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "XSssa2ZpkdY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement ResNet Architecture"
      ],
      "metadata": {
        "id": "zkJzLXOWlYwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the block class\n",
        "class ResBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        # First 3x3 convolution\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Second 3x3 convolution\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutions\n",
        "        out = self.bn1(self.conv1(x))\n",
        "        out = F.relu(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        # Adding shortcut connection\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet class\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "\n",
        "        # Initial convolution\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Stages of residual blocks\n",
        "        self.layer1 = self._make_layer(16, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(32, 3, stride=2)\n",
        "        self.layer3 = self._make_layer(64, 3, stride=2)\n",
        "\n",
        "        # Pooling\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "  def _make_layer(self, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(ResBlock(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "        out = self.bn1(self.conv1(x))\n",
        "        out = F.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "MOoDVR19kk7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defines model"
      ],
      "metadata": {
        "id": "OfxhBQOXllqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 10\n",
        "model = ResNet(num_classes=n_classes)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrNbazEHlhmV",
        "outputId": "685e9ee2-72a3-45cf-908d-0f4cff2dfda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): ResBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): ResBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): ResBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "ZzuPezdclvjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# useful libraries\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),  # Normalize to CIFAR-10 stats\n",
        "])\n",
        "\n",
        "# Preprocessing function for validation/testing data (without augmentation)\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))  # Normalize to CIFAR-10 stats\n",
        "])"
      ],
      "metadata": {
        "id": "VIPL313Hlrt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "PFjrc3gCmADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do NOT change these\n",
        "from tools.dataset import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Change this to adapt for our data\n",
        "DATA_ROOT = \"./data\"\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VAL_BATCH_SIZE = 100\n",
        "\n",
        "train_set = CIFAR10(\n",
        "    root=DATA_ROOT,\n",
        "    mode='train',\n",
        "    download=True,\n",
        "    transform=transform_train\n",
        ")\n",
        "val_set = CIFAR10(\n",
        "    root=DATA_ROOT,\n",
        "    mode='val',\n",
        "    download=True,\n",
        "    transform=transform_train\n",
        ")\n",
        "\n",
        "# construct dataloader\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=VAL_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "wnth84c0l5vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f942204-4f52-4d62-9c10-08321387f85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.dropbox.com/s/s8orza214q45b23/cifar10_trainval_F22.zip?dl=1 to ./data/cifar10_trainval_F22.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "141746176it [00:07, 18916134.88it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar10_trainval_F22.zip to ./data\n",
            "Files already downloaded and verified\n",
            "Using downloaded and verified file: ./data/cifar10_trainval_F22.zip\n",
            "Extracting ./data/cifar10_trainval_F22.zip to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy model to GPU"
      ],
      "metadata": {
        "id": "8P2rwB1-mIdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the device for computation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Deploying to: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5QAQEjTmGe1",
        "outputId": "db6cc4e5-35eb-4190-98ed-1bf736967c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deploying to: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up loss and optimizer"
      ],
      "metadata": {
        "id": "UUpUHfcrmPLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# initial learning rate\n",
        "INITIAL_LR = 0.1\n",
        "\n",
        "# momentum for optimizer\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "# L2 regularization strength\n",
        "REG = 1e-4\n",
        "\n",
        "# create loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Add optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)"
      ],
      "metadata": {
        "id": "ZfWCKMg1mKwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training Process"
      ],
      "metadata": {
        "id": "ciqL2nDcmafh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(model, criterion, optimizer, train_loader, val_loader, device, EPOCHS=100, INITIAL_LR=0.01, STEP_SIZE=30, GAMMA=0.1):\n",
        "\n",
        "  CHECKPOINT_FOLDER = '/content/drive/MyDrive/College/ece661/Project/saved_model'\n",
        "  best_val_acc = 0\n",
        "  current_learning_rate = INITIAL_LR\n",
        "\n",
        "  # Define learning rate scheduler\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "  print(\"==> Training starts!\")\n",
        "  print(\"=\"*50)\n",
        "  for i in range(0, EPOCHS):\n",
        "      # switch to train mode\n",
        "      model.train()\n",
        "\n",
        "      print(\"Epoch %d:\" %i)\n",
        "      # this help you compute the training accuracy\n",
        "      total_examples = 0\n",
        "      correct_examples = 0\n",
        "\n",
        "      train_loss = 0 # track training loss if you want\n",
        "\n",
        "      # Train the model for 1 epoch.\n",
        "      for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "          # copy inputs to device\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          # compute the output and loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          # zero the gradient\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # backpropagation\n",
        "          loss.backward()\n",
        "\n",
        "          # apply gradient and update the weights\n",
        "          optimizer.step()\n",
        "\n",
        "          # count the number of correctly predicted samples in the current batch\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_examples += targets.size(0)\n",
        "          correct_examples += (predicted == targets).sum().item()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "\n",
        "      avg_loss = train_loss / len(train_loader)\n",
        "      avg_acc = correct_examples / total_examples\n",
        "      print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "\n",
        "      # Validate on the validation dataset\n",
        "      # switch to eval mode\n",
        "      model.eval()\n",
        "\n",
        "      # this help you compute the validation accuracy\n",
        "      total_examples = 0\n",
        "      correct_examples = 0\n",
        "\n",
        "      # Track validation loss\n",
        "      val_loss = 0\n",
        "\n",
        "      # disable gradient during validation, which can save GPU memory\n",
        "      with torch.no_grad():\n",
        "          for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "              # copy inputs to device\n",
        "              inputs = inputs.to(device)\n",
        "              targets = targets.to(device)\n",
        "\n",
        "              # compute the output and loss\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, targets)\n",
        "\n",
        "              # count the number of correctly predicted samples in the current batch\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total_examples += targets.size(0)\n",
        "              correct_examples += (predicted == targets).sum().item()\n",
        "\n",
        "              val_loss += loss.item()\n",
        "\n",
        "      # Calculate average loss and average accuracy\n",
        "      avg_loss = val_loss / len(val_loader)\n",
        "      avg_acc = correct_examples / total_examples\n",
        "      print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "      # save the model checkpoint\n",
        "      if avg_acc > best_val_acc:\n",
        "          best_val_acc = avg_acc\n",
        "          if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "            os.makedirs(CHECKPOINT_FOLDER)\n",
        "          print(\"Saving ...\")\n",
        "          state = {'state_dict': model.state_dict(),\n",
        "                  'epoch': i,\n",
        "                  'lr': current_learning_rate}\n",
        "          save_path = os.path.join(CHECKPOINT_FOLDER, 'resnet_epoch_{}.pth'.format(i))\n",
        "\n",
        "          torch.save(state, save_path)\n",
        "\n",
        "      # Step learning rate scheduler\n",
        "      scheduler.step()\n",
        "      print(f\"Updated Learning Rate: {scheduler.get_last_lr()[0]}\\n\")\n",
        "\n",
        "      print('')\n",
        "\n",
        "  print(\"=\"*50)\n",
        "  print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "7jRCRaEomXDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val(model, criterion, optimizer, train_loader, val_loader, device, EPOCHS=150, INITIAL_LR=INITIAL_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGB8v6cWbvq",
        "outputId": "ace08a54-7979-4900-e740-15699c8d1b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.5939, Training accuracy: 0.4048\n",
            "Validation loss: 1.2811, Validation accuracy: 0.5306\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.0679, Training accuracy: 0.6156\n",
            "Validation loss: 1.0457, Validation accuracy: 0.6276\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 0.8175, Training accuracy: 0.7099\n",
            "Validation loss: 1.0885, Validation accuracy: 0.6284\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 0.6830, Training accuracy: 0.7629\n",
            "Validation loss: 0.7211, Validation accuracy: 0.7510\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 0.5940, Training accuracy: 0.7937\n",
            "Validation loss: 0.7858, Validation accuracy: 0.7320\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 0.5212, Training accuracy: 0.8193\n",
            "Validation loss: 0.7401, Validation accuracy: 0.7502\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 0.4676, Training accuracy: 0.8366\n",
            "Validation loss: 0.7134, Validation accuracy: 0.7550\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 0.4190, Training accuracy: 0.8535\n",
            "Validation loss: 0.6759, Validation accuracy: 0.7782\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 0.3828, Training accuracy: 0.8654\n",
            "Validation loss: 0.7717, Validation accuracy: 0.7536\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 0.3471, Training accuracy: 0.8798\n",
            "Validation loss: 0.6750, Validation accuracy: 0.7874\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 0.3192, Training accuracy: 0.8866\n",
            "Validation loss: 0.6196, Validation accuracy: 0.7934\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 0.2960, Training accuracy: 0.8959\n",
            "Validation loss: 0.8486, Validation accuracy: 0.7408\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 0.2696, Training accuracy: 0.9047\n",
            "Validation loss: 0.8921, Validation accuracy: 0.7606\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 0.2493, Training accuracy: 0.9133\n",
            "Validation loss: 0.7484, Validation accuracy: 0.7758\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 0.2332, Training accuracy: 0.9178\n",
            "Validation loss: 0.8377, Validation accuracy: 0.7724\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 0.2111, Training accuracy: 0.9257\n",
            "Validation loss: 0.7308, Validation accuracy: 0.7940\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 0.1995, Training accuracy: 0.9295\n",
            "Validation loss: 0.9964, Validation accuracy: 0.7696\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 0.1860, Training accuracy: 0.9340\n",
            "Validation loss: 0.8005, Validation accuracy: 0.7830\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 0.1746, Training accuracy: 0.9391\n",
            "Validation loss: 0.8244, Validation accuracy: 0.7712\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 0.1613, Training accuracy: 0.9427\n",
            "Validation loss: 1.0170, Validation accuracy: 0.7526\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 0.1529, Training accuracy: 0.9454\n",
            "Validation loss: 1.0105, Validation accuracy: 0.7614\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 0.1624, Training accuracy: 0.9430\n",
            "Validation loss: 0.6945, Validation accuracy: 0.8092\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 0.1341, Training accuracy: 0.9524\n",
            "Validation loss: 0.8820, Validation accuracy: 0.7906\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 0.1365, Training accuracy: 0.9499\n",
            "Validation loss: 1.0323, Validation accuracy: 0.7548\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 0.1307, Training accuracy: 0.9540\n",
            "Validation loss: 0.9625, Validation accuracy: 0.7708\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 0.1227, Training accuracy: 0.9566\n",
            "Validation loss: 0.8549, Validation accuracy: 0.7834\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 0.1244, Training accuracy: 0.9569\n",
            "Validation loss: 0.8629, Validation accuracy: 0.8012\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 0.1150, Training accuracy: 0.9596\n",
            "Validation loss: 0.8694, Validation accuracy: 0.7958\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 0.1167, Training accuracy: 0.9587\n",
            "Validation loss: 1.1122, Validation accuracy: 0.7648\n",
            "Updated Learning Rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 0.1069, Training accuracy: 0.9616\n",
            "Validation loss: 0.7903, Validation accuracy: 0.8036\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 30:\n",
            "Training loss: 0.0441, Training accuracy: 0.9868\n",
            "Validation loss: 0.6642, Validation accuracy: 0.8352\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 31:\n",
            "Training loss: 0.0177, Training accuracy: 0.9974\n",
            "Validation loss: 0.6676, Validation accuracy: 0.8356\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 32:\n",
            "Training loss: 0.0117, Training accuracy: 0.9990\n",
            "Validation loss: 0.6848, Validation accuracy: 0.8368\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 33:\n",
            "Training loss: 0.0090, Training accuracy: 0.9994\n",
            "Validation loss: 0.6844, Validation accuracy: 0.8376\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 34:\n",
            "Training loss: 0.0074, Training accuracy: 0.9996\n",
            "Validation loss: 0.6977, Validation accuracy: 0.8358\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 35:\n",
            "Training loss: 0.0063, Training accuracy: 0.9998\n",
            "Validation loss: 0.6994, Validation accuracy: 0.8360\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 36:\n",
            "Training loss: 0.0056, Training accuracy: 0.9998\n",
            "Validation loss: 0.7081, Validation accuracy: 0.8354\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 37:\n",
            "Training loss: 0.0049, Training accuracy: 0.9998\n",
            "Validation loss: 0.7135, Validation accuracy: 0.8382\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 38:\n",
            "Training loss: 0.0045, Training accuracy: 0.9999\n",
            "Validation loss: 0.7130, Validation accuracy: 0.8362\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 39:\n",
            "Training loss: 0.0041, Training accuracy: 0.9999\n",
            "Validation loss: 0.7184, Validation accuracy: 0.8370\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 40:\n",
            "Training loss: 0.0039, Training accuracy: 0.9999\n",
            "Validation loss: 0.7249, Validation accuracy: 0.8372\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 41:\n",
            "Training loss: 0.0035, Training accuracy: 1.0000\n",
            "Validation loss: 0.7254, Validation accuracy: 0.8380\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 42:\n",
            "Training loss: 0.0034, Training accuracy: 0.9999\n",
            "Validation loss: 0.7296, Validation accuracy: 0.8382\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 43:\n",
            "Training loss: 0.0031, Training accuracy: 1.0000\n",
            "Validation loss: 0.7286, Validation accuracy: 0.8372\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 44:\n",
            "Training loss: 0.0031, Training accuracy: 1.0000\n",
            "Validation loss: 0.7282, Validation accuracy: 0.8374\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 45:\n",
            "Training loss: 0.0028, Training accuracy: 1.0000\n",
            "Validation loss: 0.7331, Validation accuracy: 0.8372\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 46:\n",
            "Training loss: 0.0026, Training accuracy: 1.0000\n",
            "Validation loss: 0.7376, Validation accuracy: 0.8396\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 47:\n",
            "Training loss: 0.0027, Training accuracy: 1.0000\n",
            "Validation loss: 0.7375, Validation accuracy: 0.8382\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 48:\n",
            "Training loss: 0.0025, Training accuracy: 1.0000\n",
            "Validation loss: 0.7333, Validation accuracy: 0.8398\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 49:\n",
            "Training loss: 0.0023, Training accuracy: 1.0000\n",
            "Validation loss: 0.7339, Validation accuracy: 0.8400\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 50:\n",
            "Training loss: 0.0023, Training accuracy: 1.0000\n",
            "Validation loss: 0.7408, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 51:\n",
            "Training loss: 0.0022, Training accuracy: 1.0000\n",
            "Validation loss: 0.7471, Validation accuracy: 0.8382\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 52:\n",
            "Training loss: 0.0020, Training accuracy: 1.0000\n",
            "Validation loss: 0.7381, Validation accuracy: 0.8390\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 53:\n",
            "Training loss: 0.0020, Training accuracy: 1.0000\n",
            "Validation loss: 0.7420, Validation accuracy: 0.8402\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 54:\n",
            "Training loss: 0.0021, Training accuracy: 1.0000\n",
            "Validation loss: 0.7410, Validation accuracy: 0.8404\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 55:\n",
            "Training loss: 0.0019, Training accuracy: 1.0000\n",
            "Validation loss: 0.7428, Validation accuracy: 0.8406\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 56:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7445, Validation accuracy: 0.8386\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 57:\n",
            "Training loss: 0.0019, Training accuracy: 1.0000\n",
            "Validation loss: 0.7430, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 58:\n",
            "Training loss: 0.0019, Training accuracy: 1.0000\n",
            "Validation loss: 0.7421, Validation accuracy: 0.8406\n",
            "Updated Learning Rate: 0.010000000000000002\n",
            "\n",
            "\n",
            "Epoch 59:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7414, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 60:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7405, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 61:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7464, Validation accuracy: 0.8392\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 62:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7404, Validation accuracy: 0.8410\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 63:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7415, Validation accuracy: 0.8388\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 64:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7400, Validation accuracy: 0.8412\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 65:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7443, Validation accuracy: 0.8408\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 66:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7447, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 67:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7418, Validation accuracy: 0.8390\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 68:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7429, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 69:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7430, Validation accuracy: 0.8410\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 70:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7429, Validation accuracy: 0.8414\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 71:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7426, Validation accuracy: 0.8378\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 72:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7472, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 73:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7437, Validation accuracy: 0.8392\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 74:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7439, Validation accuracy: 0.8392\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 75:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7472, Validation accuracy: 0.8384\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 76:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7402, Validation accuracy: 0.8386\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 77:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7424, Validation accuracy: 0.8378\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 78:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7480, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 79:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7467, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 80:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7387, Validation accuracy: 0.8406\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 81:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7375, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 82:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7397, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 83:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7451, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 84:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7418, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 85:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7423, Validation accuracy: 0.8426\n",
            "Saving ...\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 86:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7413, Validation accuracy: 0.8418\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 87:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7411, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 88:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7401, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.0010000000000000002\n",
            "\n",
            "\n",
            "Epoch 89:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7427, Validation accuracy: 0.8426\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 90:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7413, Validation accuracy: 0.8412\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 91:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7447, Validation accuracy: 0.8402\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 92:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7375, Validation accuracy: 0.8402\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 93:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7411, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 94:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7347, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 95:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7360, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 96:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7457, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 97:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7448, Validation accuracy: 0.8402\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 98:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7427, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 99:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7440, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 100:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7425, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 101:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7450, Validation accuracy: 0.8382\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 102:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7451, Validation accuracy: 0.8388\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 103:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7426, Validation accuracy: 0.8386\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 104:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7387, Validation accuracy: 0.8388\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 105:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7446, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 106:\n",
            "Training loss: 0.0018, Training accuracy: 1.0000\n",
            "Validation loss: 0.7473, Validation accuracy: 0.8388\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 107:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7419, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 108:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7416, Validation accuracy: 0.8390\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 109:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7433, Validation accuracy: 0.8408\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 110:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7396, Validation accuracy: 0.8408\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 111:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7447, Validation accuracy: 0.8380\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 112:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7451, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 113:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7388, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 114:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7407, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 115:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7438, Validation accuracy: 0.8400\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 116:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7474, Validation accuracy: 0.8408\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 117:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7386, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 118:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7397, Validation accuracy: 0.8410\n",
            "Updated Learning Rate: 0.00010000000000000003\n",
            "\n",
            "\n",
            "Epoch 119:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7511, Validation accuracy: 0.8402\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 120:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7449, Validation accuracy: 0.8410\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 121:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7337, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 122:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7421, Validation accuracy: 0.8414\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 123:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7452, Validation accuracy: 0.8392\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 124:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7443, Validation accuracy: 0.8396\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 125:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7432, Validation accuracy: 0.8378\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 126:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7425, Validation accuracy: 0.8418\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 127:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7422, Validation accuracy: 0.8390\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 128:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7442, Validation accuracy: 0.8410\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 129:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7521, Validation accuracy: 0.8392\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 130:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7390, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 131:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7408, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 132:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7438, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 133:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7410, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 134:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7405, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 135:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7466, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 136:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7405, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 137:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7397, Validation accuracy: 0.8414\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 138:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7402, Validation accuracy: 0.8390\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 139:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7408, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 140:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7404, Validation accuracy: 0.8412\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 141:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7384, Validation accuracy: 0.8406\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 142:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7420, Validation accuracy: 0.8404\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 143:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7392, Validation accuracy: 0.8394\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 144:\n",
            "Training loss: 0.0015, Training accuracy: 1.0000\n",
            "Validation loss: 0.7408, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 145:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7415, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 146:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7425, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 147:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7451, Validation accuracy: 0.8406\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 148:\n",
            "Training loss: 0.0016, Training accuracy: 1.0000\n",
            "Validation loss: 0.7416, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-05\n",
            "\n",
            "\n",
            "Epoch 149:\n",
            "Training loss: 0.0017, Training accuracy: 1.0000\n",
            "Validation loss: 0.7477, Validation accuracy: 0.8398\n",
            "Updated Learning Rate: 1.0000000000000004e-06\n",
            "\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.8426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0vrFCVmWcNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}